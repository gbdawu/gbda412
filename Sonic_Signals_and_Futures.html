<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Sonic Signals and Futures - Workshops</title>

  <!-- Vuetify & Vue CDN -->
  <link href="https://cdn.jsdelivr.net/npm/vuetify@3.6.11/dist/vuetify.min.css" rel="stylesheet" />
  <script src="https://unpkg.com/vue@3/dist/vue.global.prod.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/vuetify@3.6.11/dist/vuetify.min.js"></script>
  <link href="https://cdn.jsdelivr.net/npm/@mdi/font@7.4.47/css/materialdesignicons.min.css" rel="stylesheet">

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Caveat:wght@400..700&family=Funnel+Sans:ital,wght@0,300..800;1,300..800&family=Roboto:ital,wght@0,100..900;1,100..900&display=swap"
    rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Lato&display=swap" rel="stylesheet">
  <style>
    body {
      margin: 0;
      font-family: 'Lato', sans-serif;
      background: linear-gradient(135deg, #ff416c 0%, #ff4b2b 100%);
      color: #fff;
    }

    .gradient {
      background: linear-gradient(135deg, #ff416c 0%, #ff4b2b 100%) !important;
      color: white !important;
    }

    .v-navigation-drawer {
      background: linear-gradient(135deg, #ff416c 0%, #ff4b2b 100%) !important;
      color: white !important;
      font-size: 1.2em !important;
    }

    .v-navigation-drawer .v-list-item:hover {
      background: rgba(0, 0, 0, 0.2) !important;
      color: white !important;
    }

    h1 {
      font-size: 1.75rem;
      color: #fff3f3;
      font-weight: 600;
    }

    h2 {
      font-size: 1.5rem;
      color: #ffe5e5;
      font-weight: 600;
    }

    h3 {
      font-size: 1.25rem;
      color: #fff3f3;
      font-weight: 500;
    }

    h4 {
      font-size: 1.1rem;
      color: #fff3f3;
      font-weight: 500;
    }

    h5 {
      font-size: 1rem;
      color: #ffd6d6;
    }

    .intro-section {
      font-size: 1.25rem;
      margin: 1.5rem;
      line-height: 1.6;
      color: #fff0f0;
    }

    .coming-soon-card {
      margin: 20px auto;
      background: linear-gradient(135deg, #ff416c 0%, #ff4b2b 100%);
      color: white;
    }

    .step-card {
      margin: 20px auto;
      padding: 1rem;
      border-radius: 16px;
      box-shadow: 0 8px 32px rgba(0, 0, 0, 0.08);
      background: rgba(255, 255, 255, 0.95);
      backdrop-filter: blur(10px);
      border: 1px solid rgba(255, 255, 255, 0.2);
      transition: all 0.3s ease;
      color: #4d001f;
    }

    .step-card:hover {
      transform: translateY(-4px);
      box-shadow: 0 12px 40px rgba(0, 0, 0, 0.15);
    }

    .example {
      border: none;
      padding: 20px;
      border-radius: 12px;
      background: linear-gradient(135deg, #ffb6c1 0%, #ff7f50 100%);
      margin: 20px 0;
      box-shadow: 0 4px 15px rgba(255, 65, 108, 0.2);
      border-left: 4px solid #ff416c;
    }

    .example strong {
      color: #ff4b2b;
      font-size: 1.1rem;
    }

    .custom-details summary {
      background: linear-gradient(135deg, #ff416c 0%, #ff4b2b 100%);
      color: white;
    }

    .custom-details summary:hover {
      background: linear-gradient(135deg, #ff4b2b 0%, #ff416c 100%);
    }

    .custom-details[open] summary {
      border-bottom: 2px solid rgba(255, 65, 108, 0.2);
    }

    .details-content {
      padding: 24px;
      background: linear-gradient(135deg, #ffe6eb 0%, #ffc2b3 100%);
      border-top: 1px solid rgba(255, 65, 108, 0.3);
      color: #4d001f;
    }

    .section-divider {
      margin: 32px 0;
      height: 2px;
      background: linear-gradient(90deg, transparent 0%, #ff416c 50%, transparent 100%);
      border-radius: 1px;
    }

    .learning-objectives {
      background: linear-gradient(135deg, #ffccd5 0%, #ff9990 100%);
      border-radius: 12px;
      padding: 20px;
      margin: 20px 0;
      box-shadow: 0 4px 15px rgba(255, 65, 108, 0.2);
      border-left: 4px solid #ff416c;
      color: #4d001f;
    }

    .learning-objectives h3,
    .tools-section h3 {
      color: #4d001f;
    }

    .tools-section {
      background: linear-gradient(135deg, #ffb3b3 0%, #ff7f50 100%);
      border-radius: 12px;
      padding: 20px;
      margin: 20px 0;
      box-shadow: 0 4px 15px rgba(255, 75, 43, 0.2);
      border-left: 4px solid #ff4b2b;
      color: #4d001f;
    }

    .learning-objectives ul,
    .tools-section ul {
      margin-left: 1.5rem;
      padding-left: 1.2rem;
      list-style-position: inside;
    }

    .learning-objectives li,
    .tools-section li {
      margin-bottom: 0.5rem;
    }

    a {
      color: #ff416c;
      text-decoration: none;
      font-weight: 500;
      transition: all 0.3s ease;
    }

    a:hover {
      color: #ff4b2b;
      text-decoration: underline;
    }

    code {
      background: linear-gradient(135deg, #fff0f0 0%, #ffd6d6 100%);
      padding: 4px 8px;
      border-radius: 6px;
      font-family: 'Courier New', monospace;
      color: #ff416c;
      font-weight: 600;
    }

    /* ---------- STEP STYLING ---------- */

    .step-section {
      margin: 2rem 0;
      padding: 1.5rem;
      border-radius: 18px;
      background: rgba(255, 255, 255, 0.95);
      box-shadow: 0 8px 30px rgba(255, 65, 108, 0.15);
      color: #4d001f;
      border-left: 6px solid #ff416c;
      transition: all 0.3s ease;
    }

    .step-section:hover {
      transform: translateY(-4px);
      box-shadow: 0 12px 40px rgba(255, 75, 43, 0.25);
    }

    .step-section h3 {
      font-size: 1.3rem;
      background: linear-gradient(90deg, #ff416c, #ff4b2b);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      margin-top: 0;
    }

    .step-section h4 {
      font-size: 1.10rem;
      background: linear-gradient(90deg, #ff416c, #ff4b2b);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      margin-top: 0;
    }

    .step-section h5 {
      font-size: 1rem;
      background: linear-gradient(90deg, #ff416c, #ff4b2b);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      margin-top: 0;
    }

    .step-section .objective-box {
      background: linear-gradient(135deg, #ffe6eb 0%, #ffc2b3 100%);
      border-radius: 10px;
      padding: 12px 16px;
      border-left: 4px solid #ff416c;
      margin: 1rem 0 1.5rem;
      font-weight: 500;
    }

    /* ---------- LIST STYLING ---------- */

    .step-section ol {
      list-style: decimal inside;
      counter-reset: item;
      padding-left: 1.2rem;
      line-height: 1.6;
      margin: 1rem 0;
    }

    .step-section ol>li {
      margin-bottom: 0.8rem;
      position: relative;
      padding-left: 0.5rem;
      font-size: 1rem;
    }

    .step-section ol>li::marker {
      color: #ff416c;
      font-weight: bold;
    }

    .step-section ul {
      list-style: disc;
      margin-left: 1.5rem;
      padding-left: 0.5rem;
      margin-top: 0.4rem;
    }

    .step-section ul li::marker {
      color: #ff4b2b;
    }

    .wrap-title {
      white-space: normal;
      word-break: break-word;
    }

    .styled-list {
      list-style: none;
      padding-left: 0;
    }

    .styled-list li {
      position: relative;
      padding-left: 1.5rem;
      margin: 0.75rem 0;
    }

    .styled-list li::before {
      content: 'ðŸŽ¯';
      position: absolute;
      left: 0;
      top: 0;
      font-size: 1.2rem;
    }

    .tip-box {
      border-left: 4px solid #ff416c;
      padding: 1em;
      border-radius: 12px;
      color: white;
      background-color: #454545;
    }
  </style>
</head>

<body>
  <div id="app">
    <v-app>
      <!-- App Bar -->
      <v-app-bar class="gradient" dark elevation="8">
        <v-app-bar-nav-icon @click="drawer = !drawer"></v-app-bar-nav-icon>
        <v-toolbar-title>Sonic Signals and Futures Workshops</v-toolbar-title>
      </v-app-bar>

      <!-- Navigation Drawer -->
      <v-navigation-drawer v-model="drawer" temporary>
        <v-list density="compact" nav>

          <!-- Home -->
          <v-list-item @click="tab = 0; drawer = false" prepend-icon="mdi-home" title="Home"></v-list-item>

          <!-- Stream A -->
          <v-list-group prepend-icon="mdi-cable-data">
            <template v-slot:activator="{ props }">
              <v-list-item v-bind="props">
                <v-list-item-title class="wrap-title">
                  Stream A: Biofeedback Practice
                </v-list-item-title>
              </v-list-item>
            </template>

            <v-list-item v-for="(step, index) in streamAWorkshops" :key="'a-'+index"
              @click="tab = 1; scrollToStep(index, 'A'); drawer = false">
              <v-list-item-title class="wrap-title">{{ step.title }}</v-list-item-title>
            </v-list-item>
          </v-list-group>

          <!-- Stream B -->
          <v-list-group prepend-icon="mdi-robot">
            <template v-slot:activator="{ props }">
              <v-list-item v-bind="props">
                <v-list-item-title class="wrap-title">
                  Stream B: Creative Music Machines"
                </v-list-item-title>
              </v-list-item>
            </template>

            <v-list-item v-for="(step, index) in streamBWorkshops" :key="'b-'+index"
              @click="tab = 2; scrollToStep(index, 'B'); drawer = false">
              <v-list-item-title class="wrap-title">{{ step.title }}</v-list-item-title>
            </v-list-item>
          </v-list-group>

        </v-list>
      </v-navigation-drawer>

      <!-- Main Content -->
      <v-main>
        <v-container class="py-10">

          <v-window v-model="tab" mandatory>

            <!-- Home -->
            <v-window-item value="0">
              <h2>Welcome to the Sonic Signals and Futures Workshops</h2>
              <div class="intro-section">
                <p>Welcome to a series of workshops where you will experiment with personal experiences, technology,
                  and creative processes to explore the intersections of movement, sound, and digital tools.</p>
                <br>
                <p>Through hands-on activities, youâ€™ll engage with either your body or artificial intelligence to
                  generate musical works. You will explore different streams that offer distinct approaches to music
                  creation, learning how physical activity, AI, and creative experimentation can produce expressive,
                  sonic outcomes.</p>
                <br>
                <ul class="styled-list">
                  <li>Stream A â€“ <b>The Body as Instrument:</b> Explore how personal bio-data can generate unique sonic
                    experiences that reflect movement, gesture, and the physicality of the body. Collect your own GPS
                    data using Strava or wearable devices (e.g., Apple Watch, Fitbit) and sonify it using online
                    sequencers or other tools to create experimental musical outcomes.</li>
                  <li>Stream B â€“ <b>Creative Music Machines:</b> Explore how artificial intelligence tools can help you
                    generate music. Using the online tool ElevenLabs, you will collaborate with AI to produce music
                    compositions from text prompts, experimenting with mood, style, structure, and instruments in an
                    interactive, co-creative process.</li>
                </ul>

              </div>
            </v-window-item>

            <!-- Stream A -->
            <!-- Workshop 1 -->
            <v-window-item :value="1">
              <!-- <h2>Stream A: Biofeedback Practice</h2> -->
              <h2>{{ streamAWorkshops[0].title }}</h2>
              <div class="intro-section">
                <p> In this workshop, you will explore how physical movement can generate data that can
                  be transformed into sound. Using the Strava app, you will record a short
                  activityâ€”such as walking around campus, taking a short route to get coffee, or any
                  movement of your choice. This activity will allow you to capture your own
                  biofeedback data and begin to understand how bodily motion can be represented as
                  digital information. </p> <br>
                <h3><v-icon color="primary" class="mr-2">mdi-walk</v-icon>What You Will Do</h3>
                <p> You will record a 1-minute movement session using Strava, download your activity
                  data as a CSV file from the Strava desktop platform, and convert it into a MIDI file
                  using <a href="https://gbdawu.github.io/gbda412/csv-to-midi" target="_blank">csv to midi mapper</a>.
                  You will then upload the resulting
                  MIDI file into <a href="https://onlinesequencer.net/" target="_blank">Online Sequencer</a> to
                  experiment with different instruments and sonic textures. This process introduces
                  how the bodyâ€™s movement can become a musical source. </p> <br>
                <p> The outcome of this workshop will serve as preparation for <strong>Project 2, Part
                    1: Proposal & Concept Development</strong>, where you will describe your own
                  planned activity and how you intend to creatively transform movement data into
                  sound. </p>


                <br>

                <div class="learning-objectives">
                  <h3><v-icon color="primary" class="mr-2">mdi-target</v-icon>Learning Objectives</h3>
                  <ul>

                    <li>Understand how motion-based data can be transformed into music by
                      converting it into a MIDI file.</li>
                    <li>Reflect on how your movement patterns and choices influence the
                      resulting music and consider what this reveals about using the body as an
                      instrument.</li>
                    <li>Generate material and insights to support <strong>Project 2, Part 1:
                        Proposal & Concept Development</strong>.</li>
                  </ul>
                </div>

                <br>
                <div class="tools-section">
                  <h3><v-icon color="primary" class="mr-2">mdi-tools</v-icon>Tools you'll use</h3>
                  <ul>
                    <li>Strava app on your smartphone</li>
                    <li>Strava desktop dashboard</li>
                    <li>FIT/GPX to CSV Converter </li>
                    <li>CSV-to-MIDI Mapper</li>
                    <li>Online Sequencer</li>
                  </ul>
                </div>
              </div>

              <!-- Steps -->

              <br>
              <div class="section-divider"></div>
              <div class="step-section">

                <h3><v-icon color="primary" class="mr-2">mdi-walk</v-icon>1: Record Your Movement Data
                  in Strava
                </h3>
                <div class="objective-box"> <strong>Objective:</strong> Use the Strava app to record a
                  short movement activity and generate your own motion data for later sound
                  transformation. </div>
                <p>Follow these steps:</p>
                <ol>
                  <li> Install the Strava app on your mobile device. <ul>
                      <li>Link to Strava on the Apple App Store: <a
                          href="https://apps.apple.com/us/app/strava-run-bike-walk/id426826309" target="_blank">Install
                          Strava App</a> </li>
                      <li>Link to Strava on Google Play: <a
                          href="https://play.google.com/store/apps/details?id=com.strava&hl=en_CA"
                          target="_blank">Install Strava App</a>

                        <v-img src="images/biofeedback/strava-app.jpeg" alt="Strava app screenshot"
                          class="my-4 rounded-lg" width="20%" />
                      </li>
                    </ul>
                  </li>
                  <li> Go outside and complete a short activity of your choice (for example, walking
                    around campus, going for a coffee, or exploring nearby paths). <ul>
                      <li>Open Strava, tap <strong>Record</strong> â†’ <strong>Start</strong> to
                        begin tracking your movement.</li>
                      <li>Move for about <strong>1 minute</strong> while the app records your
                        route and motion data.
                        <v-img src="images/biofeedback/strava-app-record.png" alt="Strava recording interface"
                          class="mx-2 rounded-lg" max-width="40%" />
                      </li>
                      <li>When you are finished, tap <strong>Stop</strong> â†’
                        <strong>Finish</strong> â†’ <strong>Save</strong> to save the motion data
                        from your activity.
                        <v-img src="images/biofeedback/strava-app-stop.png" alt="Strava recording interface"
                          class="mx-2 rounded-lg" max-width="20%" />
                      </li>
                    </ul>
                  </li>
                  <li> Return to the classroom </li>

                </ol>
              </div>

              <div class="section-divider"></div>
              <div class="step-section">

                <h3><v-icon color="primary" class="mr-2">mdi-laptop</v-icon>2: Download and Convert Your
                  Strava Data</h3>
                <div class="objective-box"> <strong>Objective:</strong> Access your recorded activity
                  data
                  from the Strava desktop platform, export it as a <b>FIT</b> or <b>GPX</b> file, and convert it into a
                  CSV
                  format for later sound transformation. </div>
                <p>Follow these steps:</p>
                <ol>
                  <li> On your computer, navigate to the Strava website: <a href="https://www.strava.com/"
                      target="_blank">https://www.strava.com/</a>
                  </li>
                  <li> Click <strong>Log In</strong> and choose your preferred login method: <ul>
                      <li><strong>Email and Password:</strong> Enter the email address and
                        password
                        associated with your account.</li>
                      <li><strong>Email and Code:</strong> Send a one-time code to your email
                        address and password
                        associated with your account.</li>
                      <li><strong>Linked Account:</strong> Select <em>Google</em>, <em>Apple</em>,
                        or
                        <em>Facebook</em> if youâ€™ve linked your Strava profile.
                      </li>
                      <li>Click the <strong>Log In</strong> button to continue.</li>
                    </ul>
                  </li>
                  <li> After logging in, go to your profile: <ul>
                      <li>Click your name or profile icon in the upper-right corner of the page.
                      </li>
                      <li>From the top menu, select <strong>Training â†’ My Activities</strong>.
                        <v-img src="images/biofeedback/my-activities.png" alt="Strava recording interface"
                          class="mx-2 rounded-lg" max-width="60%" />
                      </li>
                      <li>Locate the activity you recorded earlier and click it to open its detail
                        page.
                        <v-img src="images/biofeedback/activity-detail.png" alt="Strava recording interface"
                          class="mx-2 rounded-lg" max-width="60%" />
                      </li>
                    </ul>
                  </li>
                  <li> Export your data as a GPX or FIT file: <ul>
                      <li>Click the <strong>three-dots icon (<v-icon color="primary"
                            class="mx-1">mdi-dots-vertical</v-icon>) </strong> in the top-left corner
                        of
                        the activity page.</li>
                      <li>Select <strong>Export GPX</strong> or <strong>Export Original (FIT file)</strong> from the
                        dropdown menu.
                        <v-img src="images/biofeedback/export-gpx.png" alt="Strava recording interface"
                          class="mx-2 rounded-lg" max-width="60%" />
                      </li>
                      <li>The file will automatically download to your computer.</li>
                    </ul>
                  </li>

                  <li><b>Convert your GPX or FIT file into a CSV</b>.
                    <ul>
                      <li>If you downloaded a <b>FIT file</b>, use the
                        <a href="https://gotoes.org/strava/convert_fit_files_to_csv.php" target="_blank">
                          FIT to CSV converter</a>.
                      </li>

                      <li>If you downloaded a <b>GPX file</b>, use the
                        <a href="https://gbdawu.github.io/gbda412/gpx-to-csv" target="_blank">
                          GPX to CSV converter</a>.
                      </li>
                    </ul>
                  </li>
                </ol>
              </div>


              <div class="section-divider"></div>
              <div class="step-section">
                <h3><v-icon color="primary" class="mr-2">mdi-file-music</v-icon>3: Map CSV Data to MIDI
                </h3>
                <div class="objective-box"> <strong>Objective:</strong> Transform your recorded motion
                  data
                  into a musical format by mapping the data in your <strong>FIT</strong> or <strong>GPX</strong> file
                  into
                  a
                  MIDI file.
                  <br><br>
                  <div><strong> What is
                      MIDI?</strong>
                    <p> MIDI (Musical Instrument Digital Interface) is a digital file format that
                      stores
                      information about notes, timing, and instrument data â€” not actual recorded
                      sound. It
                      allows different software and hardware instruments to interpret musical
                      data,
                      making
                      it possible to edit, remix, or reassign sounds to the same musical
                      structure.
                    </p>
                  </div>
                </div>



                <p>Follow these steps:</p>
                <ol>




                  <li> Go to the CSV-to-MIDI Mapper webpage: <a href="https://gbdawu.github.io/gbda412/csv-to-midi"
                      target="_blank">https://gbdawu.github.io/gbda412/csv-to-midi</a> </li>
                  <li> Load your CSV file

                    <v-img src="images/biofeedback/csv-to-midi.png" alt="Strava recording interface"
                      class="mx-2 rounded-lg" max-width="60%" />
                  <li> Under <strong>Column Mappings</strong>, choose the parameters you want to map. For example:
                    <ul>
                      <li><strong>X</strong> or <strong>Y</strong> for the <em>Note</em></li>
                      <li><strong>time</strong> for <em>Time</em> and <em>Duration</em></li>
                      <li><strong>X</strong> or <strong>Y</strong> for the <em>Velocity</em>
                      <li><strong>track_seg_point_id</strong> or <strong>speed</strong> for <em>Octave</em>

                        <v-img src="images/biofeedback/mapping.png" alt="Strava recording interface"
                          class="mx-2 rounded-lg" max-width="60%" />
                      </li>
                    </ul>
                  </li>
                  <li> Experiment with other musical parameters such as <strong>scale</strong>,
                    <strong>root note</strong>, and
                    <strong>amplification</strong>. Donâ€™t worry if youâ€™re not sure what each one means â€” we
                    will
                    explore these settings in more detail in future workshops.
                    <br>
                    <v-img src="images/biofeedback/musical-settings.png" alt="Strava recording interface"
                      class="mx-2 rounded-lg" max-width="55%" />
                  </li>

                  <li> Once youâ€™re satisfied with your configuration, <b>save your new MIDI</b> file by
                    clicking
                    <b>Validate Data</b> â†’ <b>Download Midi</b>
                    at the bottom of the page.

                    <v-img src="images/biofeedback/save-mapping.png" alt="Strava recording interface"
                      class="mx-2 rounded-lg" max-width="60%" />
                  </li>
                </ol>
              </div>

              <div class="section-divider"></div>
              <div class="step-section">
                <h3><v-icon color="primary" class="mr-2">mdi-music</v-icon>4: Listen to Your MIDI File
                  in
                  Online Sequencer</h3>
                <div class="objective-box"> <strong>Objective:</strong> Upload and listen to your MIDI
                  file
                  in an online sequencer to hear how your movement data translates into music. </div>
                <p>Follow these steps:</p>
                <ol>
                  <li> Go to <a href="https://onlinesequencer.net/" target="_blank">Online
                      Sequencer</a>.
                  </li>
                  <li> On the top menu, click the <strong>three dots</strong> (<v-icon color="primary"
                      class="mx-1">mdi-dots-vertical</v-icon>) and select <strong>Import
                      MIDI/Sequence File</strong>.

                    <v-img src="images/biofeedback/import-midi.png" alt="Strava recording interface"
                      class="mx-2 rounded-lg" max-width="60%" />
                  </li>
                  <li> In the <strong>Import MIDI</strong> window that appears: <ul>
                      <li>Select an instrument from the dropdown menu (for example, Piano, Synth,
                        or
                        Strings).</li>
                      <li>Click <strong>Import</strong> to load your MIDI file into the sequencer.
                      </li>
                    </ul>
                  </li>
                  <li> Click <v-icon color="primary" class="mx-1">mdi-play</v-icon>
                    to listen to your composition â€” this is the sound
                    representation of your movement data from Strava. When finished, click
                    <v-icon color="primary" class="mx-1">mdi-stop</v-icon> to
                    stop the playback.
                  </li>
                </ol>
              </div>

              <div class="section-divider"></div>
              <div class="step-section">

                <h3><v-icon color="primary" class="mr-2">mdi-account-group</v-icon>5: Share Your
                  Music With the Class</h3>
                <div class="objective-box"> <strong>Objective:</strong> Share your music sequence
                  created from your movement data in Online Sequencer with the class and explore the
                  variety of results generated from your physical activities. </div>
                <ol>
                  <li> In Online Sequencer, click the <strong>Cloud</strong> <v-icon color="primary"
                      class="mx-1">mdi-cloud</v-icon> icon at the top menu
                    corner of the interface.

                    <ul>
                      <li>This will generate a unique URL for your sequence.</li>
                      <li>Copy the URL provided â€” this is the link you will share with the class.

                        <v-img src="images/biofeedback/share-url.png" alt="Strava recording interface"
                          class="mx-2 rounded-lg" max-width="60%" />
                      </li>
                    </ul>
                  </li>
                  <li> Post the URL on the class whiteboard: <a href="https://tinyurl.com/SonicSignalsAndFutures"
                      target="_blank">https://tinyurl.com/SonicSignalsAndFutures</a>
                  </li>
                  <li> Once posted, take a few minutes to listen to your classmatesâ€™ sequences. Notice
                    how different movement patterns, speeds, and routes have resulted in unique
                    musical outcomes. </li>
                </ol>
              </div>

              <div class="section-divider"></div>
              <div class="step-section">

                <h3><v-icon color="primary" class="mr-2">mdi-file-document-outline</v-icon>6: Develop
                  Your Proposal and Concept</h3>
                <div class="objective-box"> <strong>Objective:</strong> Use your experience recording
                  and listening to your movement data to begin drafting your Project 2, Part 1:
                  Proposal & Concept Development.
                  <br><br>
                  <p><strong>Note:</strong> There is no submission required at this step. A good idea
                    is to start
                    your draft during class so you can refine it at home before posting it
                    on Avenue to Learn by the date indicated in the guidelines.</p>
                </div>
                <p>Follow these steps to start developing ideas that will form the basis of your
                  proposal:</p>
                <ol>
                  <li> Reflect on the physical activity you completed: <ul>
                      <li>What did you notice about your body, movement patterns, or rhythm while
                        capturing the data?</li>
                      <li>How did your pace, gestures, or decisions about where to move influence
                        the sounds produced in your MIDI sequence?</li>
                    </ul>
                  </li>
                  <li> Imagine how you want to transform your GPS/movement data into music: <ul>
                      <li>What types of sounds or instruments could represent your heartbeat,
                        speed, or movement?</li>
                      <li>How might different musical elements (pitch, rhythm, dynamics) convey
                        aspects of your physical activity?</li>
                    </ul>
                  </li>
                  <li> Consider connections to course discussions and readings: <ul>
                      <li>How does your concept relate to ideas of embodiment, sound, and
                        technology?</li>
                      <li>How might your work explore the body as a site of musical expression or
                        affective feedback?</li>
                    </ul>
                  </li>
                  <li> Begin drafting your <strong>Project 2, Part 1: Proposal & Concept
                      Development</strong>: <ul>
                      <li>Use the guidelines provided here: <a
                          href="https://gbdawu.github.io/gbda412/group-project-2.html"
                          target="_blank">https://gbdawu.github.io/gbda412/group-project-2.html</a>
                      </li>

                    </ul>
                  </li>
                </ol>
              </div>

            </v-window-item>

            <!-- Workshop 2 -->
            <v-window-item value="2">
              <h2>{{ streamAWorkshops[1].title }}</h2>

              <div class="intro-section">
                <p> In this workshop, you will take a deeper dive into your movement data and explore
                  how creative mapping decisions can transform raw biofeedback into expressive sound.
                  Building on Workshop 1, where you converted movement into MIDI, you will record yourself again and
                  open
                  and examine the actual CSV data to understand what information your body generates
                  during movementâ€”such as GPS coordinates, elevation, speed, and optionally, heart rate. </p> <br>

                <h3><v-icon color="primary" class="mr-2">mdi-map-marker-path</v-icon>What You Will Do</h3>
                <p> You will record another 1-minute movement session using Strava (with heart rate data
                  if your device supports it), then download and convert your activity data to CSV format. This time,
                  you will open the CSV file to explore its structure and the
                  different data columns it contains. After, using the <a
                    href="https://gbdawu.github.io/gbda412/csv-to-midi" target="_blank">CSV-to-MIDI
                    Converter</a>, you will create three different MIDI variations by experimenting with
                  different mapping strategies for notes, velocity, time, duration, scales, octaves, and ranges.
                </p>
                <br>
                <p> The outcomes of this workshop will help you refine your theme and generate materials for the
                  <strong>Project 2,
                    Part 2: Materials Collection</strong> due November 2.
                </p>

                <br>

                <div class="learning-objectives">
                  <h3><v-icon color="primary" class="mr-2">mdi-target</v-icon>Learning Objectives</h3>
                  <ul>
                    <!-- <li>Reflect on how your physical movement and bodily experience influence
                      the character and quality of the resulting music.</li> -->
                    <li>Understand the structure of GPS and biometric data by examining CSV file
                      columns (X, Y, elevation, heart rate, time).</li>
                    <li>Learn to make creative map your data to musical variables like pitch, velocity, key, scale,
                      octave, duration, and timing.</li>
                    <!-- <li>Experiment with musical variables (note, velocity, key, scale, octave, range) to shape
                      how your movement data sounds.</li> -->
                    <li>Generate draft materials for <strong>Project 2, Part 2: Materials
                        Collection</strong> and refine your overall theme and concept.</li>
                  </ul>
                </div>

                <br>

                <div class="tools-section">
                  <h3><v-icon color="primary" class="mr-2">mdi-tools</v-icon>Tools you'll use</h3>
                  <ul>
                    <li>Strava app on your smartphone or watch (with optional heart rate monitor connection)</li>
                    <li>Strava desktop dashboard</li>
                    <li>FIT/GPX to CSV Converter </li>
                    <li>CSV-to-MIDI Mapper</li>
                    <li>Online Sequencer</li>
                    <li>Spreadsheet software (Excel, Google Sheets, or Numbers) to view CSV data</li>
                  </ul>
                </div>
              </div>

              <!-- Steps -->


              <br>
              <div class="section-divider"></div>
              <div class="step-section">
                <h3><v-icon color="primary" class="mr-2">mdi-notebook-edit</v-icon>Step 1: Refine Your Proposal and
                  Deepen Your Concept</h3>

                <div class="objective-box"><strong>Objective:</strong> Revisit and refine your Project 2, Part 1:
                  Proposal & Concept Development. Your theme will guide your data collection and mapping decisions.
                </div>

                <ol>
                  <li><strong>Revisit your proposal from the discussion forum.</strong> Remind yourself of the activity
                    and concept you initially proposed. You can also see what other people are planning by reading the
                    proposals on the discussion forum on LEARN.</li>



                  <li><strong>Consider connections to course discussions and readings:</strong>
                    <ul>
                      <li>How does your concept relate to ideas of embodiment, sound, feminism, and technology?</li>
                      <!-- <li>How does your concept explore the body as a site of data generation and musical expression?
                      </li> -->
                      <li>What does it mean to translate body signals into digital information and then
                        into sound?</li>
                      <li>How might your work reveal or question the relationship between physical experience and
                        technological mediation?</li>
                    </ul>
                  </li>

                  <li><strong>Refine your proposal:</strong> Write down a refined theme
                    statement (1-2 sentences). Keep it flexible â€” your theme can evolve as you gather data and ideas.
                    <ul>
                      <li><b>If you haven't submitted a proposal yet, use this step to start your initial theme proposal
                          (consult guidelines on LEARN).</b></li>
                    </ul>
                  </li>
                </ol>
              </div>


              <div class="section-divider"></div>
              <div class="step-section">
                <h3><v-icon color="primary" class="mr-2">mdi-run</v-icon>Step 2: Record Your Movement Data
                </h3>


                <div class="objective-box"><strong>Objective:</strong> Capture a new 1-minute activity using Strava,
                  this time being more
                  intentional about creating variation in your movement data that will translate into interesting sonic
                  material.


                </div>

                <p>Follow these steps:</p>
                <ol>
                  <li><strong>Plan a new activity with intentional variation.</strong> In Workshop 1, you may have
                    noticed that
                    some aspects of your data didn't vary much. For this
                    recording, try to create more diversity in your movement data:
                    <ul>
                      <li><strong>To create variation in longitude and latitude (X, Y):</strong> Make turns, walk in
                        curved
                        or zigzag patterns, trace shapes (circles, squares, figure-eights), or change direction
                        frequently
                        rather than walking in a straight line.</li>

                      <li><strong>To create silence or longer notes:</strong> Pause during your walk, or slow down
                        significantly for a few seconds. The timestamps in your data will be farther apart, creating
                        longer
                        note durations.</li>

                      <li><strong>To create elevation changes:</strong> Walk up and down stairs (e.g., first floor to
                        third
                        floor), move through a building with multiple levels, or find outdoor terrain with hills or
                        slopes.
                      </li>
                      <br>
                      <div class="tip-box">
                        <p><strong>ðŸ’¡ Think of your activity as a mini performance. Your body's choicesâ€”where you move,
                            how
                            fast,
                            when you pauseâ€”are compositional decisions that will shape your final sound. Some activity
                            suggestions are:</strong>
                        <ul>
                          <li>Walk up and down a stairwell multiple times</li>
                          <li>Trace a specific pattern or shape around a building or courtyard</li>
                          <li>Walk through different rooms or hallways with intentional pauses</li>
                          <li>Move between indoor and outdoor spaces</li>
                          <li>Create a "choreographed" walk with specific movements in mind</li>
                        </ul>
                        </p>
                      </div>
                    </ul>
                  </li>

                  <li><b>Go outdoors to record for 1 minute</b> using the Strava app.
                    <ul>
                      <li>Consult workshop 1 to see detailed instructions on how to record using Strava.</li>
                      <br>
                      <div class="tip-box">
                        <p><strong>ðŸ’¡</strong> If you have an Apple Watch, Fitbit, or other heart rate-enabled device,
                          you
                          can
                          connect it to
                          Strava to capture heart rate data alongside your GPS data. To connect your device follow the
                          instructions in the video below.
                        </p>
                      </div>
                      <br>
                      <iframe width="560" height="315"
                        src="https://www.youtube.com/embed/g4KLEA0kyMc?si=FW_eGFy4WOVKnuRy" title="YouTube video player"
                        frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                        referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

                    </ul>
                  </li>
                  <li>After recording, <b>download your activity from Strava</b>.
                    <ul>
                      <li>It is recommended to download the <b>Fit file</b>, as it contains additional data such as
                        <em>speed</em>,
                        <em>distance</em>, and <em>heart rate</em> (if connected to the Strava app). The <b>GPX file</b>
                        can also be used,
                        but may
                        have less interesting data fields.
                      </li>
                      <br>
                      <li>Instructions to download:
                        <ol>
                          <li>From the top menu on Strava Desktop, select <b>Training â†’ My Activities</b>.</li>
                          <li>Locate the activity you recorded and click to open its detail page.</li>
                          <li>Click the three-dots icon (<v-icon color="primary"
                              class="mx-1">mdi-dots-vertical</v-icon>) in the top-left corner of the activity page.</li>
                          <li>Select <b>Export GPX</b> or <b>Export Original (Fit file)</b> from the dropdown menu.</li>
                          <div class="tip-box">
                            <p><strong>ðŸ’¡</strong> Consult workshop 1 to see detailed instructions on how to download
                              your data
                              from Strava.

                            </p>
                          </div>
                        </ol>
                      </li>
                    </ul>
                  </li>



                </ol>
              </div>

              <div class="section-divider"></div>

              <div class="step-section">
                <h3><v-icon color="primary" class="mr-2">mdi-file-chart</v-icon>Step 3: Convert and Explore
                  Your Data</h3>

                <div class="objective-box"><strong>Objective:</strong> Convert your FIT or GPX file to CSV format and
                  examine
                  the data structure to understand what information your body generated
                  during movement. You will also begin planning how to structure your composition by analyzing the
                  time
                  column.</div>

                <ol>

                  <li><b>Convert your activity file into a CSV</b>.
                    <ul>
                      <li>If you downloaded a <b>FIT file</b>, use the
                        <a href="https://gotoes.org/strava/convert_fit_files_to_csv.php" target="_blank">
                          FIT to CSV converter</a>.
                      </li>

                      <li>If you downloaded a <b>GPX file</b>, use the
                        <a href="https://gbdawu.github.io/gbda412/gpx-to-csv" target="_blank">
                          GPX to CSV converter</a>.
                      </li>
                    </ul>
                  </li>

                  <li><strong>Open your generated CSV file</strong> in Excel or Google Sheets to explore the raw data
                    recorded
                    during your movement.</li>

                  <li><strong>Examine the column headers</strong>. Depending on whether you exported a FIT or GPX file,
                    you will see different sets of data:
                    <ul>
                      <li><strong>timestamp:</strong> The exact moment each sample was recorded
                        <em>(available in both FIT and GPX files)</em>
                      </li>

                      <li><strong>latitude / longitude:</strong> Your geographic position at each moment
                        <em>(available in both FIT and GPX files)</em>
                      </li>



                      <li><strong>altitude:</strong> Elevation above sea level
                        <em>(available in FIT file)</em>
                      </li>

                      <li><strong>heart_rate:</strong> Your heart rate in beats per minute
                        <em>(available in FIT if you recorded with your watch)</em>
                      </li>

                      <li><strong>speed:</strong> Your instantaneous speed in meters per second
                        <em>(available in FIT file)</em>
                      </li>

                      <li><strong>distance:</strong> Total cumulative distance traveled
                        <em>(available in FIT file)</em>
                      </li>
                      <li><strong>track_seg_point_id:</strong> The sequential index of each GPS point in the recording
                        <em>(available in GPX file)</em>
                      </li>

                      <li><strong>ele (elevation):</strong> Your elevation above sea level at each GPS point
                        <em>(available in GPX file)</em>
                      </li>

                    </ul>
                  </li>


                  <li><strong>Look at your data patterns. Scroll through the spreadsheet and observe how the numbers
                      change row by row.</strong>
                    <ul>

                      <li>Look at how latitude and longitude shiftâ€”large changes mean you moved farther or changed
                        direction</li>
                      <li>See how the timestamp increases with each movement you made</li>
                      <li>Notice where elevation changes significantlyâ€”these were moments you moved up or down</li>
                      <li>If you have heart rate data, observe where it peaks or drops</li>
                    </ul>
                  </li>
                </ol>


                <div class="tip-box">
                  <p><strong>ðŸ’¡ Tip:</strong> Understanding your data structure now will help you make intentional
                    creative decisions in the next step when you map this data to musical parameters. Take your time
                    with this explorationâ€”it's where you start to see your body as data!</p>
                </div>
              </div>

              <div class="section-divider"></div>
              <div class="step-section">
                <h3><v-icon color="primary" class="mr-2">mdi-music-note</v-icon>Step 4: Create 3 MIDI Variations
                  Through
                  Data Mapping</h3>

                <div class="objective-box"><strong>Objective:</strong> Use the CSV-to-MIDI Converter to transform your
                  movement data into sound
                  by experimenting with different mapping strategies. You will create three distinct MIDI variations
                  by
                  changing which data columns become notes, velocity, time, and duration parameters, and by adjusting
                  key, scale, octave, and range settings.</div>



                <div class="tip-box">
                  <p><strong>ðŸ’¡ Understanding Data-to-MIDI Mapping</strong></p>

                  <p>Mapping is the creative process of deciding which aspects of your body's data become which
                    aspects
                    of sound. Different mapping choices create dramatically different sonic results from the same
                    data.
                  </p>
                  <ul>
                    <li><strong>Note:</strong> <em>Which data column controls which notes are played?</em> Usually
                      longitude or latitude coordinates. The CSV-to-MIDI converter scales your latitude/longitude
                      decimal
                      coordinates down to the MIDI note range (0-127), where each number represents a different pitch.
                      <span style="text-decoration: underline">Small changes in your coordinates create small pitch
                        changes</span>,
                      while <span style="text-decoration: underline">larger movements create bigger melodic
                        leaps</span>.
                    </li>
                    <li><strong>Velocity:</strong> <em>Which data column controls how loud or soft notes are?</em>
                      Could be elevation, heart rate, or the other coordinate axis.
                    </li>
                    <li><strong>Duration:</strong> <em>Which data column controls how long each note lasts?</em>
                      Try the X or Y. When you move slowly or pause, numbers are farther
                      apart,
                      creating longer notes. Moving quickly creates shorter, more rapid notes.
                    </li>
                    <li><strong>Time:</strong> <em>What data controls time in your music composition?</em>
                      The time column can be used to determine when notes play.
                    </li>
                  </ul>

                  <!-- <p><strong>ðŸ’¡ Understanding the Musical Parameters</strong></p>
                   <p>Before creating your variations, familiarize yourself with the parameters you can adjust in the :</p>

                <ul>
                  <li><strong>Key:</strong> The root note of your scale (e.g., C, D, Eâ™­). Changing the key shifts all
                    your notes up or down in pitch.
                    <ul>
                      <li><em>Example: C Major sounds bright and open; Dâ™­ Major sounds slightly darker and more
                          mysterious.</em></li>
                    </ul>
                  </li>

                  <li><strong>Scale:</strong> The set of notes available in your composition. Different scales create
                    different moods.
                    <ul>
                      <li><em>Major scales:</em> Often sound happy, bright, or uplifting</li>
                      <li><em>Minor scales:</em> Often sound sad, contemplative, or dramatic</li>
                      <li><em>Pentatonic scales:</em> Sound neutral, open, and often "Asian-inspired"</li>
                      <li><em>Chromatic:</em> Uses all 12 notesâ€”can sound dissonant, experimental, or jazzy</li>
                      <li><em>Example: The same walk mapped in C Major will sound cheerful, while in C Minor it will
                          sound melancholic.</em></li>
                    </ul>
                  </li>

                  <li><strong>Octave:</strong> How high or low your notes sound overall. Lower octaves sound deeper
                    and
                    heavier; higher octaves sound lighter and brighter.
                    <ul>
                      <li><em>Example: Octave 3-4 sounds warm and middle-range; Octave 5-6 sounds bright and
                          bell-like.</em></li>
                    </ul>
                  </li>

                  <li><strong>Range:</strong> How many octaves your melody can span. A wider range creates more
                    dramatic
                    pitch changes; a narrower range sounds more constrained.
                    <ul>
                      <li><em>Example: A range of 1 octave keeps melodies simple; a range of 3 octaves allows for big
                          leaps and dynamic movement.</em></li>
                    </ul>
                  </li>
                </ul> -->

                </div>

                <ol>
                  <li><strong> Upload your CSV file to <a href="https://gbdawu.github.io/gbda412/csv-to-midi"
                        target="_blank">CSV-to-MIDI converter</a> </strong>
                    <v-img src="images/biofeedback/csv-to-midi.png" alt="Keyboard example showing octaves"
                      class="my-4 rounded-lg" width="50%"></v-img>
                  </li>

                  <li><strong>Create 3 MIDI Variations using CSV-to-MIDI converter</strong>. Now you'll create three
                    different sonic interpretations of your
                    movement data. For each variation,
                    you'll change the mapping strategy and adjust musical parameters as follows:

                    <ol>
                      <li>Variation 1: East-West Movement as Melody
                        <ul>
                          <li>Under <strong>Column Mappings</strong>, set:
                            <ul>
                              <li><strong>Notes:</strong> Select the <strong>Longitude column</strong> â€”
                                this maps your east-west movement to pitch</li>
                              <li><strong>Velocity:</strong> Select the <strong>ele (elevation)</strong> column or
                                <strong>altitude</strong> column â€” this
                                makes
                                changes in height affect note loudness
                              </li>
                              <li><strong>Time:</strong> Select the <strong>timestamp</strong> column</li>
                              <li><strong>Duration:</strong> Select the <strong>Latitude</strong> column</li>

                            </ul>
                          </li>
                          <li>Choose musical parameters:
                            <ul>
                              <li><strong>Root note:</strong> Try C or D</li>
                              <li><strong>Scale:</strong> Try Major or Pentatonic</li>
                              <li><strong>Octave:</strong> Try the Distance Column</li>
                              <li><strong>Amplification:</strong> Try 100x</li>
                            </ul>
                          </li>
                          <li>Click <strong>Convert</strong> or <strong>Generate MIDI</strong> to create your file.</li>
                          <li>Download and save it as <code>longitude-melody.mid</code>.
                          </li>
                        </ul>
                      </li>

                      <li>Variation 2: North-South Movement as Melody
                        <ul>
                          <li>Under <strong>Column Mappings</strong>, set:
                            <ul>
                              <li><strong>Notes:</strong> This time, select the <strong>Latitude </strong> â€” this maps
                                your
                                north-south movement to pitch</li>
                              <li><strong>Velocity:</strong> Try <strong>hr (heart rate)</strong> if available, or
                                <strong>ele
                                  (elevation)</strong> if not
                              </li>
                              <li><strong>Time:</strong> Select the <strong>timestamp</strong> column</li>
                              <li><strong>Duration:</strong> Select the <strong>Longitude</strong> column</li>
                            </ul>
                          </li>
                          <li>Change musical parameters to create contrast with Variation 1:
                            <ul>
                              <li><strong>Root note:</strong> Try a different key (e.g., A or Eâ™­)</li>
                              <li><strong>Scale:</strong> Try Minor </li>
                              <li><strong>Octave:</strong> Try the Latitude column</li>
                              <li><strong>Amplification:</strong> Try 400x</li>
                            </ul>
                          </li>
                          <li>Generate and download as <code>latitude-melody.mid</code>.</li>
                        </ul>
                      </li>

                      <li>Variation 3: Elevation or Heart Rate as Melody
                        <ol>
                          <li>Under <strong>Column Mappings</strong>, set:
                            <ul>
                              <li><strong>Notes:</strong> Select <strong>altitude</strong> or <strong>ele
                                  (elevation)</strong> â€” this makes your
                                vertical
                                movement the melody</li>
                              <li><strong>Velocity:</strong> Select <strong>Longitude or Latitude</strong> - this will
                                make your
                                east-west/north-south make your notes louder or softer.</li>
                              <li><strong>Time:</strong> Select the <strong>timestamp</strong> column</li>
                              <li><strong>Duration:</strong> Select the the <strong>timestamp</strong> column or
                                <strong>track_seg_point_id</strong> column
                              </li>

                              <li><em>Alternative if you have heart rate data: Use <strong>hr</strong> as notes and
                                  <strong>ele</strong> as velocity to hear your heartbeat as melody</em></li>
                            </ul>
                          </li>
                          <li>Experiment with a completely different sonic palette:
                            <ul>
                              <li><strong>Root note:</strong> Try something unexpected (e.g., Fâ™¯ or Bâ™­)</li>
                              <li><strong>Scale:</strong> Try Chromatic or another scale you haven't used</li>
                              <li><strong>Octave:</strong> Try the Speed column</li>
                              <li><strong>Amplification:</strong> Try 800x
                              </li>
                            </ul>
                          </li>
                          <li>Generate and download as <code>elevation_melody.mid</code> or
                            <code>heart-rate_melody.mid</code>.
                          </li>
                        </ol>
                      </li>
                    </ol>
                  </li>
                </ol>
              </div>

              <div class="section-divider"></div>
              <div class="step-section">
                <h3><v-icon color="primary" class="mr-2">mdi-piano</v-icon>Step 5: Sonic Exploration and Final Outputs
                </h3>

                <div class="objective-box"><strong>Objective:</strong> Import each of your 3 MIDI variations into
                  Online Sequencer, experiment with different instruments to bring out unique sonic qualities in your
                  data, and export your final 3 audios for submission in Project 2, Part 2: Materials
                  Collection.</div>

                <ol>


                  <li>For each of your 3 MIDI variations try several different instruments:
                    <ul>
                      <li>Import one MIDI file at a time into <a href="https://onlinesequencer.net/"
                          target="_blank">Online Sequencer</a>
                        <ul>
                          <li>See Worksop 1 for detailed instructions on how to import into Onlie Sequencer.</li>
                        </ul>
                      </li>
                      <li><strong>Try contrasting instruments for each variation</strong> to create sonic diversity
                        across your three outputs. For example:
                        <ul>
                          <li>Variation 1 (longitude-based melody): Piano or Marimba</li>
                          <li>Variation 2 (latitude-based melody): Strings or Synth Pad</li>
                          <li>Variation 3 (elevation or heart rate melody): Flute or Synth Lead</li>
                        </ul>

                        <div class="tip-box">
                          <p><strong>ðŸ’¡ Creative Tip:</strong> Don't just pick your "favorite" soundâ€”choose instruments
                            that
                            tell different stories about your movement. One might emphasize the physicality, another the
                            geography, and another the emotional quality of your walk.</p>
                        </div>
                      </li>

                      <li><strong>Consider which instrument best reveals the quality of movement in each
                          variation:</strong>
                        <ul>
                          <li>Does this variation have sharp, sudden changes? â†’ Try percussive instruments</li>
                          <li>Does it have smooth, flowing patterns? â†’ Try sustained instruments like strings</li>
                          <li>Does it emphasize physical effort or heart rate? â†’ Try organic wind instruments or
                            bass</li>
                          <li>Does it feel abstract or experimental? â†’ Try synths or unconventional choices</li>
                        </ul>
                      </li>

                      <li><strong>Listen for what each instrument emphasizes:</strong>
                        <ul>
                          <li>Does the instrument make the rhythm more prominent or the melody?</li>
                          <li>Does it highlight the high notes or low notes in your data?</li>
                          <li>Does it create an emotional quality that connects to your bodily experience?</li>
                        </ul>
                      </li>
                    </ul>
                  </li>

                  <li>Export Your 3 Final Outputs. Once you've chosen the best instrument for each of your 3 MIDI
                    variations, you'll export them as
                    MP3 files for submission.
                    <ul>
                      <li>In Online Sequencer, with your MIDI file loaded and your chosen instrument selected, click the
                        <strong>Cloud â˜ icon</strong> at the top corner of the interface.
                      </li>
                      <li>Click <strong>Export MP3</strong>.</li>
                      <li>Save the file with a descriptive name that helps you remember which variation and instrument
                        it uses (e.g., <code>variation1-piano.mp3</code>, <code>latitude-melody-strings.mp3</code>,
                        <code>elevation-synth.mp3</code>).
                      </li>
                    </ul>
                  <li>Repeat this process for all 3 of your MIDI variations with their chosen instruments.</li>
                  </li>
                </ol>
              </div>



              <div class="section-divider"></div>
              <div class="step-section">
                <h3><v-icon color="primary" class="mr-2">mdi-file-document-outline</v-icon>Step 6: Document Your Work
                  for Project 2, Part 2: Materials Collection</h3>

                <div class="objective-box">
                  <strong>Objective:</strong> Prepare documentation of your creative process and materials for
                  submission in <strong>Project 2, Part 2: Materials Collection</strong> on LEARN. This documentation
                  will help you articulate your mapping decisions, reflect on the relationship between body and sound,
                  and envision your final project direction.
                </div>

                <p>Take notes on the following to prepare for your forum post:</p>

                <ol>
                  <li><strong>For each of your 3 outputs, document:</strong>
                    <ul>
                      <li>Which MIDI variation is this? (What mapping strategy did you use?)</li>
                      <li>Which instrument did you choose and why?</li>
                      <li>What quality of your movement does this instrument/mapping combination emphasize or reveal?
                      </li>
                    </ul>
                  </li>

                  <li><strong>Prepare to discuss how this material connects to your proposal and to course
                      readings:</strong>
                    <ul>
                      <li>How does your work explore embodimentâ€”the lived experience of your body in motion?</li>
                      <li>What does the process of converting bodily data to sound reveal about the relationship
                        between the body, technology, and musical expression?</li>
                      <li>How does this connect to ideas from course readings about sound, the body, affect, or
                        biofeedback?</li>
                    </ul>
                  </li>

                  <li><strong>Describe what kinds of instruments, timbres, or sounds you imagine using when composing
                      your final project from this data:</strong>
                    <ul>
                      <li>Will you layer multiple instruments?</li>
                      <li>Do you want acoustic, electronic, or hybrid sounds?</li>
                      <li>What sonic atmosphere or emotional quality are you aiming for?</li>
                      <li>How might your instrument choices reflect the physical experience of the activity you
                        recorded?</li>
                    </ul>
                  </li>
                </ol>

                <br>

                <div class="tip-box">
                  <p><strong>ðŸ’¡ Ready to Submit? </strong></p>
                  <p>You now have everything you need for <strong>Project 2, Part 2: Materials Collection</strong>:
                  </p>
                  <ul>
                    <li>âœ… 1 CSV with your data recorded </li>
                    <!-- <li>âœ… 3 MIDI variations (with different mapping strategies)</li> -->
                    <li>âœ… 3 MP3 sonic explorations (with different instruments)</li>
                    <li>âœ… Documentation of your creative decisions and connections to course concepts</li>
                  </ul>
                  <p>Upload your materials and post your reflection in the forum on LEARN by the deadline.
                    Consult the project guidelines for full submission requirements: <a
                      href="https://gbdawu.github.io/gbda412/group-project-2.html" target="_blank">Project 2
                      Guidelines</a></p>
                </div>
              </div>

            </v-window-item>

            <!-- Workshop 3 -->
            <v-window-item value="3">
              <h2>{{ streamAWorkshops[2].title }}</h2>

              <div class="intro-section">

                <p>
                  In this workshop, you will shift from data mapping to <strong>musical arrangement</strong>.
                  Using the melody you previously generated from your movement data (Workshop 2), you will learn
                  how to shape it into a richer, more expressive musical idea inside
                  <a href="https://onlinesequencer.net/" target="_blank">Online Sequencer</a>.
                  This workshop focuses on practical creative strategiesâ€”adding harmony, bass, and rhythmâ€”even if
                  you have no musical background.
                </p>
                <br>

                <p>
                  <em>
                    If youâ€™re curious about generating new data, or if you want to explore more detailed metrics such as
                    <strong>speed</strong> and <strong>distance</strong>, you may revisit Workshop 2 and try working
                    with a FIT file. FIT data often contains richer information than GPX and can lead to more nuanced
                    musical results. You are also encouraged to try the <a
                      href="https://gbdawu.github.io/gbda412/csv-to-midi" target="_blank"> CSV-to-MIDI Mapper</a>
                    developed for this
                    class,
                    which offers more flexible mapping options than the tool used last week.
                    However, for this session, using the MIDI melody you already created in Workshop 2 is completely
                    fine but may generate less interesting outputs.
                  </em>
                </p>

                <br>

                <h3><v-icon color="primary" class="mr-2">mdi-map-marker-path</v-icon>What You Will Do</h3>
                <p>
                  You will import your CSV-to-MIDI melody into Online Sequencer and learn how to shape it into a fuller
                  composition by adding <strong>harmony</strong> (supporting notes), <strong>bass</strong> (foundation),
                  and <strong>rhythm</strong> (pulse and movement).
                  These techniques will help you transform an experimental, data-driven melody into a more structured,
                  expressive, and aesthetically engaging musical sketch.

                </p>
                <br>

                <div class="learning-objectives">
                  <h3><v-icon color="primary" class="mr-2">mdi-target</v-icon>Learning Objectives</h3>
                  <ul>
                    <li>Practice arranging music visually using the Draw tool inside Online Sequencer.</li>
                    <li>Learn the basic concepts of <strong>harmony</strong>, <strong>bass</strong>,
                      and <strong>rhythm</strong> through simple, non-theoretical explanations.</li>
                    <li>Create a short musical sketch that builds on your movement-derived melody and prepares you
                      for later collaborative composition work.</li>
                  </ul>
                </div>

                <br>

                <div class="tools-section">
                  <h3><v-icon color="primary" class="mr-2">mdi-tools</v-icon>Tools you'll use</h3>
                  <ul>
                    <li>Your previously recorded movement data (CVS file from Workshop 2)</li>
                    <li>CSV-to-MIDI Converter (to re-export your melody if needed)</li>
                    <li><a href="https://onlinesequencer.net/" target="_blank">Online Sequencer</a></li>

                  </ul>
                </div>

              </div>

              <!-- Steps -->

              <br>
              <div class="section-divider"></div>
              <div class="step-section">
                <h3><v-icon color="primary" class="mr-2">mdi-music-note-plus</v-icon>Step 1: Import Your MIDI and
                  Explore the Sequencer</h3>

                <div class="objective-box">
                  <strong>Objective:</strong> Import your MIDI file into <a href="https://onlinesequencer.net/"
                    target="_blank">Online Sequencer</a> and explore basic sequencing features.
                </div>

                <ol>
                  <li><strong>Import your MIDI file:</strong> Use the MIDI file generated from Workshop 2, or try the
                    <a href="https://gbdawu.github.io/gbda412/csv-to-midi" target="_blank"> CSV-to-MIDI Mapper</a> for
                    richer options.
                    <ul>
                      <li>Click <b> (<v-icon color="primary" class="mx-1">mdi-dots-vertical</v-icon>) â†’ Import
                          MIDI/Sequence File</b> in Online Sequencer and select your file.</li>
                      <li>Your MIDI file will now appear as a melody track in the sequencer grid.</li>
                    </ul>
                  </li>

                  <li><strong>Explore Online Sequencer interface</strong> by playing with the following aspects of your
                    MIDI file:
                    <ul>
                      <li>Tempo (speed) adjustment</li>
                      <li>Using the drawing tool to add or edit notes</li>
                      <li>Instrument selection </li>
                      <li>Watch this video tutorial to learn how:</li>
                      <iframe width="560" height="315"
                        src="https://www.youtube.com/embed/Y-LJxTnRKQM?si=WhM4jHCEisPDolVp" title="YouTube video player"
                        frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                        referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

                    </ul>
                  </li>


                </ol>
              </div>


              <div class="section-divider"></div>
              <div class="step-section">
                <h3><v-icon color="primary" class="mr-2">mdi-notebook-edit</v-icon>Step 2: Creative Layering with
                  Harmony</h3>

                <div class="objective-box"><strong>Objective:</strong> Add harmonic layers to your main melody to enrich
                  the musical texture and experiment with complementary sounds.</div>

                <p>
                  <b> Harmony</b> is when multiple notes play together to create a
                  richer sound. In this step, you'll experiment with adding complementary or supporting notes to your
                  main melody.

                </p>

                <ol>


                  <li><strong>Choose a harmonic instrument:</strong> Pick an instrument like a piano or synth pad that
                    works well for sustained notes (pads). This will form the base of your harmonic layer.
                    <v-img src="images/biofeedback/electric-piano.png" alt="Keyboard example showing octaves"
                      class="my-4 rounded-lg" width="15%"></v-img>

                  </li>

                  <li><strong>Analyze your melody:</strong> Look at the notes in your imported MIDI track and decide
                    which notes you want to support with harmony. Think of harmony as adding â€œcolorâ€ to your melody.

                    <v-img src="images/biofeedback/single-notes.png" alt="Keyboard example showing octaves"
                      class="my-4 rounded-lg" width="30%"></v-img>
                  </li>

                  <li><strong>Experiment with octaves:</strong> An <em>octave</em> is the same note, higher or lower.
                    For example, C5 played one octave lower is C4. You can add harmonic notes in the same
                    octave or an octave above/below to make your track sound fuller. <b>In the example below, the green
                      notes are the imported notes from your data and the blue notes are octaves drawn with the Draw
                      Tool:</b>
                    <v-img src="images/biofeedback/octave-harmony-short-notes.png"
                      alt="Keyboard example showing octaves" class="my-4 rounded-lg" width="30%"></v-img>
                  </li>

                  <li><strong>Create long notes (pads):</strong> In Online Sequencer, drag notes to extend their length.
                    These sustained notes can support your main melody, creating a smooth background layer.
                    <v-img src="images/biofeedback/octave-harmony.png" alt="Keyboard example showing octaves"
                      class="my-4 rounded-lg" width="30%"></v-img>
                  </li>

                  <li><strong>Playful intervals: 3rd and 5th</strong>:
                    <ul>
                      <li>Imagine your melody notes as stepping stones.</li>
                      <li>For each harmonic note, place a â€œbuddyâ€ note 2 steps above (3rd) or 4 steps above (5th) in the
                        scale.
                        This creates consonant harmony.</li>
                      <li>Donâ€™t worry about exact theoryâ€”just try moving notes up by 3 or 4 steps and listen: it should
                        sound pleasing!

                        <v-img src="images/biofeedback/3rd-notes.png" alt="Keyboard example showing octaves"
                          class="my-4 rounded-lg" width="30%"></v-img>
                      </li>
                    </ul>
                  </li>

                  <li><strong>Layer and listen:</strong> Play your harmonic track together with your main melody. Adjust
                    note placement and length until the combination sounds rich and coherent. Remember: experimentation
                    is key!</li>
                </ol>
              </div>


              <div class="section-divider"></div>
              <div class="step-section">
                <h3><v-icon color="primary" class="mr-2">mdi-music-note</v-icon>Step 3: Add a Bass Layer</h3>

                <div class="objective-box">
                  <strong>Objective:</strong> Enhance your melody by adding a bass line that gives depth and rhythm to
                  your composition.
                </div>

                <p>A <strong>bass line</strong> is a sequence of low-pitched notes that support the main melody. It can
                  make your music feel fuller, drive the rhythm, and create a sense of movement.</p>

                <ol>
                  <li><strong>Choose a bass instrument:</strong> Pick an instrument such as <em>Bass</em> or <em>Bass
                      Guitar</em> in Online Sequencer.

                    <v-img src="images/biofeedback/bass-dropdown.png" alt="Keyboard example showing octaves"
                      class="my-4 rounded-lg" width="10%"></v-img>
                  </li>
                  <li><strong>Place notes in lower octaves:</strong> Remember, an <strong>octave</strong> is the same
                    note, higher or lower. For example, C4 has the next C one octave
                    lower at C3.
                    <v-img src="images/biofeedback/bassC3.png" alt="Keyboard example showing octaves"
                      class="my-4 rounded-lg" width="30%"></v-img>
                  </li>
                  <li><strong>Tips for creating playful bass lines:</strong>
                    <ul>
                      <li>Use the same <strong>notes</strong> of your main melody for cohesion.</li>
                      <li>Experiment with <strong>repeating patterns</strong> that echo your melody in a simpler way.
                      </li>

                      <li>Keep your bass notes <strong>longer and simpler</strong> than your melody to avoid
                        overcrowding the sound.</li>
                      <li>See the following video starting in minute 6:33 to get an idea on how to add a bass line:
                        <iframe width="560" height="315"
                          src="https://www.youtube.com/embed/nuEkOA8qBDs?si=4phjNdPXc9Bvl2w6"
                          title="YouTube video player" frameborder="0"
                          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                          referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    </ul>
                  </li>
                  </li>
                  <li><strong>Experiment freely:</strong> Explore different octaves, note lengths, and rhythmic
                    placement.</li>
                </ol>

              </div>


              <div class="section-divider"></div>
              <div class="step-section">
                <h3><v-icon color="primary" class="mr-2">mdi-drum</v-icon>Step 4: Explore Rhythm and Percussion</h3>

                <div class="objective-box">
                  <strong>Objective:</strong> Add rhythmic layers to your composition to give movement and groove to
                  your melody, harmony, and bass tracks.
                </div>

                <p>
                  <b>Rhythm</b> is the pattern of sounds over time that gives music its
                  pulse and energy.
                </p>
                <ol>


                  <li><strong>Choose percussion instruments:</strong> Open the instrument dropdown in Online Sequencer
                    and explore the <strong>Percussion</strong> section. You can try instruments like:
                    <ul>
                      <li>Kick drum â€“ for a steady pulse</li>
                      <li>Snare â€“ adds snap and accent</li>
                      <li>Hi-hat or cymbals â€“ for texture and faster patterns</li>
                      <li>Other playful percussion sounds â€“ anything you like!</li>
                      <v-img src="images/biofeedback/drumset-dropdown.png" alt="Keyboard example showing octaves"
                        class="my-4 rounded-lg" width="10%"></v-img>
                    </ul>
                  </li>

                  <li><strong>Create your rhythmic pattern:</strong>
                    <ul>
                      <li>Use the draw tool to add notes on the percussion track, experimenting with different timing
                        and placement.</li>
                      <li>Try layering patterns with your bass and melody â€” you can create contrast by having some
                        instruments play on every beat, and others on off-beats.</li>

                      <li>Check the following video showing how to create a drum kit rhythm starting in minute 5:54:
                        <iframe width="560" height="315"
                          src="https://www.youtube.com/embed/k1B1n4tsQdw?si=A6Mf8GVoKrjzye7I&amp;start=352"
                          title="YouTube video player" frameborder="0"
                          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                          referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                      </li>
                    </ul>
                  </li>

                </ol>
              </div>


            </v-window-item>


            <!-- STREAM B -->

            <v-window-item value="4">
              <h2>{{ streamBWorkshops[0].title }}</h2>
              <div class="intro-section">
                <p>In this workshop, you will explore how AI can be used to generate original music. Using ChatGPT and
                  the ElevenLabs AI music creator, you will design a short 30-second composition. This process will
                  allow you to experiment with musical ideas, styles, and textures, while discovering how human
                  creativity can collaborate with machine intelligence.</p> <br>

                <h3><v-icon color="primary" class="mr-2">mdi-music-note</v-icon>What You Will Do</h3>
                <p>
                  You will follow define mood, genre, and sections and use ChatGPT to craft prompts for the
                  ElevenLabs AI music creator. You will enter your prompts into ElevenLabs to generate a
                  30-second piece, then save the resulting audio file.
                </p>

                <p>The outcome of this workshop will serve as preparation for <strong>Project 2, Part 1: Proposal &
                    Concept Development</strong>, where you will formalize your AI music project and explain your
                  creative process.</p>



                <!-- <h3><v-icon color="primary" class="mr-2">mdi-map</v-icon>What is GPS Drawing?</h3>
                            <p>Also known as GPS art, GPS drawing is a method where an artist uses a Global
                                Positioning System (GPS) device to follow a pre-planned route and create a
                                large-scale picture or pattern. The .GPX data recorded during the drawing process is
                                visualized as a line on a map. Artists often run or cycle the route, while cars,
                                boats, or planes can be used for larger artworks. <a
                                    href="https://en.wikipedia.org/wiki/GPS_drawing" target="_blank">Learn more</a>.
                            </p> -->

                <br>

                <div class="learning-objectives">
                  <h3><v-icon color="primary" class="mr-2">mdi-target</v-icon>Learning Objectives</h3>
                  <ul>
                    <li>Understand how to use AI tools like ChatGPT and ElevenLabs to generate short musical
                      compositions based on prompts and creative direction.</li>
                    <li>Reflect on how your creative decisionsâ€”such as mood, genre, instruments, and structureâ€”shape the
                      resulting AI-generated music.</li>
                    <li>Produce and document material that will support <strong>Project 2, Part 1: Proposal & Concept
                        Development</strong>, outlining your concept and musical approach.</li>
                  </ul>
                </div>


                <br>
                <div class="tools-section">
                  <h3><v-icon color="primary" class="mr-2">mdi-tools</v-icon>Tools you'll use</h3>
                  <ul>
                    <li>ChatGPT</li>
                    <li>ElevenLabs</li>
                  </ul>
                </div>
              </div>

              <!-- Steps -->

              <br>
              <div class="section-divider"></div>
              <div class="step-section">

                <h3><v-icon color="primary" class="mr-2">mdi-music-note</v-icon>1: Define Mood, Genre, & Sections</h3>
                <div class="objective-box">
                  <strong>Objective:</strong> Describe the mood, genre, and overall structure
                  of your AI-generated music
                  composition. Indicate if lyrics will be included.
                </div>
                <p>Follow these steps:</p>
                <ol>
                  <li>Think about the emotional tone or feeling you want your 30-second composition to convey. Consider
                    genres and rhythms that align with your vision.</li>
                  <li>Sketch a rough outline of your musical sections (for example: intro, build-up, climax, ending) and
                    note any specific instruments or sonic elements you plan to include.
                  </li>
                  <li>If you plan to include lyrics, jot down a couple short phrases or words that capture the mood of
                    your
                    piece.
                  </li>
                  <li>Finalize your ideas so that they are clear enough to create prompts for Step 2 with ChatGPT and
                    ElevenLabs AI music creator.</li>
                </ol>

              </div>

              <div class="section-divider"></div>
              <div class="step-section">

                <h3><v-icon color="primary" class="mr-2">mdi-music-note</v-icon>2: Develop Prompts with ChatGPT</h3>
                <div class="objective-box">
                  <strong>Objective:</strong> Use ChatGPT to develop effective prompts for ElevenLabs AI music creator.
                  Decide on mood, instruments, and structure for your 30-second composition.
                </div>

                <p>Follow these steps:</p>
                <ol>
                  <li>
                    Go to <a href="https://chatgpt.com/" target="_blank">ChatGPT</a> and start a new conversation. <ul>
                      <li>Explain the exercise: you want to develop a 30-second AI-generated music composition.</li>
                      <li>Ask ChatGPT to ask you questions about mood/emotional tone, instruments, and
                        musical structure you want.</li>
                      <li>Request that ChatGPT asks the questions <strong>one at a time</strong>, for example: 3
                        questions about mood, 3 about instruments, 3 about structure.</li>
                      <li>Follow this example prompt for ChatGPT:

                        <v-img src="images/AIMusic/prompt1.png" alt="ElevenLabs account creation"
                          class="my-4 rounded-lg" width="60%" />
                      </li>
                    </ul>
                  </li>

                  <li>
                    Answer ChatGPT's questions thoughtfully, describing the mood, genre, instruments, and sections of
                    your composition.
                    <v-img src="images/AIMusic/prompt2.png" alt="ElevenLabs account creation" class="my-4 rounded-lg"
                      width="60%" />
                  </li>

                  <li>
                    Once all questions are answered, ask ChatGPT to generate a list of prompts for ElevenLabs AI music
                    creator. <ul>
                      <li>Ensure each prompt is concise, clear, and can be directly input into ElevenLabs to produce
                        your 30-second music piece.</li>

                      <li><strong>Example:</strong>
                        <v-img src="images/AIMusic/prompt3.png" alt="ElevenLabs account creation"
                          class="my-4 rounded-lg" width="60%" />
                      </li>

                    </ul>
                  </li>

                  <li>Save the resulting list of prompts for use in the next step when generating your music in
                    ElevenLabs.</li>
                </ol>

              </div>


              <div class="section-divider"></div>
              <div class="step-section">
                <h3><v-icon color="primary" class="mr-2">mdi-music-note</v-icon>3: Generate Music in ElevenLabs</h3>
                <div class="objective-box"><strong>Objective:</strong> Use the prompts you developed with ChatGPT to
                  generate a 30-second music composition in ElevenLabs AI music creator, and save the resulting audio
                  file for later use.</div>
                <p>Follow these steps:</p>
                <ol>
                  <li>Create an ElevenLabs account using your Waterloo University email. <ul>
                      <li>Go to <a href="https://www.elevenlabs.io/" target="_blank">ElevenLabs AI music creator</a> and
                        click <strong>Sign Up</strong>.</li>
                      <li>Select the <strong>Free Account</strong> option.</li>
                      <li><strong>Disclaimer:</strong> If you choose to explore the topic of AI music, please note that
                        some platforms may require a $5 USD one-month subscription. In many cases, the free version may
                        be sufficient, but the subscription could be necessary to fully complete the assignment.</li>
                    </ul>
                  </li>
                  <li>Open the music generation interface. <ul>
                      <li>Locate the input field where you can enter your text prompts.</li>
                    </ul>
                  </li>
                  <li>Enter the prompts generated with ChatGPT into the input field. <ul>
                      <li>These prompts should describe mood, instruments, structure, and any other instructions for
                        your 30-second piece.</li>
                      <li><v-img src="images/AIMusic/elevenlabs1.png" alt="ElevenLabs example prompt"
                          class="my-4 rounded-lg" width="60%" /></li>
                    </ul>
                  </li>
                  <li>Click <strong>Generate</strong> to produce your 30-second composition. <ul>
                      <li>Listen to your generated audio using the play button.</li>
                      <li><strong>Recommendation:</strong> Avoid tweaking the prompts now, as this will use up your
                        monthly music generation minutes. Save them for next weekâ€™s workshop!
                        <v-img src="images/AIMusic/elevenlabs2.png" alt="ElevenLabs play button" class="my-4 rounded-lg"
                          width="60%" />
                      </li>
                    </ul>
                  </li>

                </ol>
              </div>

              <div class="section-divider"></div>
              <div class="step-section">
                <h3><v-icon color="primary" class="mr-2">mdi-share-variant</v-icon>4: Share Your Composition on the
                  Class Whiteboard</h3>
                <div class="objective-box"><strong>Objective:</strong> Upload your AI-generated 30-second music
                  composition to the shared class whiteboard so that your peers can listen, comment, and engage with
                  your work.</div>
                <p>Follow these steps:</p>
                <ol>

                  <li>Copy the <strong> Share Page</strong> link from ElevenLabs. <ul>
                      <li>Click the <strong>Share</strong> button at the bottom of ElevenLabs Music Creator.</li>
                      <li>Select <strong>Share Public Page</strong>.
                        <v-img src="images/AIMusic/elevenlabs3.png" alt="ElevenLabs play button" class="my-4 rounded-lg"
                          width="60%" />

                      </li>
                    </ul>
                  </li>

                  <li>Post the Public Page link in the class whiteboard. <ul>
                      <li>Post the link to <a href="https://tinyurl.com/SonicSignalsAndFutures"
                          target="_blank">https://tinyurl.com/SonicSignalsAndFutures</a>.</li>
                    </ul>
                  </li>

                  <li>Listen to other compositions. <ul>
                      <li>Explore compositions uploaded by your classmates and take notes for inspiration.</li>
                    </ul>
                  </li>
                </ol>
              </div>

              <div class="section-divider"></div>
              <div class="step-section">

                <h3><v-icon color="primary" class="mr-2">mdi-file-document-outline</v-icon>5: Develop Your Proposal and
                  Concept</h3>
                <div class="objective-box">
                  <strong>Objective:</strong> Use your experience developing prompts, generating music, and
                  experimenting with AI to begin drafting your <strong>Project 2, Part 1: Proposal & Concept
                    Development</strong>.
                  <br><br>
                  <p><strong>Note:</strong> There is no submission required at this step. A good idea is to start your
                    draft during class so you can refine it at home before posting it on Avenue to Learn by the date
                    indicated in the guidelines.</p>
                </div>

                <p>Follow these steps to start developing ideas that will form the basis of your proposal:</p>
                <ol>
                  <li>Reflect on your AI music creation process:
                    <ul>
                      <li>Which moods, genres, or emotional tones did you explore in your prompts?</li>
                      <li>How did your choices for instruments, textures, or structure influence the generated audio?
                      </li>
                      <li>What aspects of your prompt crafting or iteration process affected the outcome?</li>
                    </ul>
                  </li>
                  <li>Envision your composition:
                    <ul>
                      <li>Outline the general musical sections you plan for a final, longer, 2-3 minutes piece (e.g.,
                        intro, verse,
                        chorus, bridge, outro).</li>
                      <li>Decide if your composition will include lyrics, and if so, whether you will write them
                        yourself or use AI-generated text.</li>
                    </ul>
                  </li>
                  <li>Connect your concept to course themes:
                    <ul>
                      <li>How does your AI music composition relate to ideas of automation, creativity, and
                        humanâ€“machine collaboration?</li>
                      <li>How does your work engage with readings and discussions on algorithmic composition,
                        AI-generated music, or digital remix cultures?</li>
                    </ul>
                  </li>
                  <li>Begin drafting your <strong>Project 2, Part 1: Proposal & Concept Development</strong>:
                    <ul>
                      <li>Use the guidelines provided here: <a
                          href="https://gbdawu.github.io/gbda412/group-project-2.html"
                          target="_blank">https://gbdawu.github.io/gbda412/group-project-2.html</a></li>
                    </ul>
                  </li>
                </ol>

              </div>

            </v-window-item>

            <!-- Workshop 2 -->
            <v-window-item value="5">
              <h2>{{ streamBWorkshops[1].title }}</h2>

              <div class="intro-section">
                <p>
                  In this workshop, you will deepen your AI prompting skills to produce complex and
                  expressive music compositions.
                  You will also practice on structuring a longer composition of
                  one to one and a half minutes, by generating individual sections such as an intro and verse.
                  Through this process, youâ€™ll deepen your
                  understanding of how
                  descriptive language can shape musical ideas and guide AI tools toward your creative vision.
                </p>
                <br>

                <h3>
                  <v-icon color="primary" class="mr-2">mdi-music-note</v-icon>
                  What You Will Do
                </h3>

                <p>
                  You will start by refining your proposal's idea. The, you will use ChatGPT to develop detailed prompts
                  for two song sections like an
                  intro and a verse and generate these sections
                  with the
                  ElevenLabs AI music creator. Once youâ€™ve produced your sections, youâ€™ll export and document your
                  results for
                  <strong>Project 2, Part 2: Materials Collection</strong>.
                </p>






                <br>

                <div class="learning-objectives">
                  <h3><v-icon color="primary" class="mr-2">mdi-target</v-icon>Learning Objectives</h3>
                  <ul>
                    <li>Develop skills in prompt engineering for effective
                      creative collaboration between you and AI systems.
                    </li>
                    <li>Practice with structuring longer compositions by generating and combining multiple sections
                      such as intros and verses.</li>
                    <li>Produce and document material that will support <strong>Project 2, Part 2: Materials
                        Collection</strong>, including prompts, outputs, and reflections on your process.</li>
                  </ul>
                </div>

                <br>

                <div class="tools-section">
                  <h3><v-icon color="primary" class="mr-2">mdi-tools</v-icon>Tools you'll use</h3>
                  <ul>
                    <li>ChatGPT</li>
                    <li>ElevenLabs</li>
                  </ul>
                </div>

              </div>

              <!-- Steps -->


              <div class="section-divider"></div>
              <div class="step-section">
                <h3><v-icon color="primary" class="mr-2">mdi-notebook-edit</v-icon>Step 1: Refine Your Proposal and
                  Deepen Your Concept</h3>

                <div class="objective-box">
                  <strong>Objective:</strong> Revisit and refine your Project 2, Part 1: Proposal & Concept
                  Development. Your theme will guide your creative decisions.
                </div>

                <ol>
                  <li><strong>Revisit your proposal from the discussion forum.</strong> Remind yourself of the activity
                    and concept you
                    initially proposed. You can also see what other people are planning by reading the proposals on the
                    discussion forum on LEARN.
                  </li>

                  <li><strong>Connect your concept to readings from week 10 about AI and creativity:</strong>
                    <ul>
                      <li>How does your approach respond to debates about authorship and originality in AI-generated
                        music?</li>
                      <li>What creative decisions remain human in your process, and which ones are delegated to machine
                        intelligence?</li>
                      <li>How might platform-based tools (like ChatGPT and ElevenLabs) influence the aesthetics or
                        accessibility of your work?</li>
                      <li>What tensions or opportunities emerge when human intuition meets algorithmic generation?</li>
                    </ul>
                  </li>

                  <li><strong>Refine your proposal:</strong> Write down a refined theme statement (1-2 sentences). Keep
                    it flexible â€”
                    your theme can evolve as you gather data and ideas.
                    <ul>
                      <div class="tip-box">
                        <strong>ðŸ’¡</strong> If you haven't submitted a proposal yet, use this step to start your
                        initial theme
                        proposal
                        (consult
                        guidelines on LEARN).
                      </div>

                    </ul>
                  </li>
                </ol>
              </div>

              <div class="section-divider"></div>
              <div class="step-section">

                <h3><v-icon color="primary" class="mr-2">mdi-music-note</v-icon>Step 2: Define Mood, Genre & Sections
                </h3>
                <div class="objective-box">
                  <strong>Objective:</strong> Outline the overall mood, genre, and structure of your AI-generated
                  composition.
                  Plan the main sections of your piece (e.g., intro, verse, chorus) and consider how each section
                  contributes to the flow of the music.
                </div>

                <div class="tip-box">

                  <strong>ðŸ’¡ What are Mood, Genre & Sections:</strong>
                  <ul>
                    <li><strong>Mood:</strong> The emotional feeling of your piece, e.g., energetic, melancholic,
                      mysterious.</li>
                    <li><strong>Genre:</strong> The style or category of music, e.g., pop, rock, country, electronic,
                      dance.</li>
                    <li><strong>Sections:</strong> The main parts of your composition, like intro, verse, chorus, or
                      bridge. Each section can have its own mood and instrumentation.</li>
                  </ul>
                </div>
                <br>

                <p>In a piece of paper or notepad brainstorm:</p>
                <ol>
                  <li> The emotional tone or feeling you want your composition to convey (for example: energetic,
                    melancholic,
                    mysterious).
                    <ul>
                      <li>Think about the genre
                        that best fits this mood (for example: pop, rock, country, electronic,
                        dance).</li>
                    </ul>
                  </li>
                  <li>Decide 2 sections of your composition (for example: intro and verse, or verse and
                    chorus).
                    <ul>
                      <li>Brainstorm what music instruments each section will have (for example: drums, shakers, guitar,
                        bass, keyboard, vocals) </li>
                      <li>Decide the length of these sections (for example: intro plays for 15 seconds, verse plays for
                        1 minute) </li>
                    </ul>
                  </li>
                </ol>
              </div>


              <div class="section-divider"></div>
              <div class="step-section">

                <h3><v-icon color="primary" class="mr-2">mdi-music-note</v-icon>Step 3: Develop Prompts for Individual
                  Sections</h3>
                <div class="objective-box">
                  <strong>Objective:</strong> Use ChatGPT to develop effective prompts for ElevenLabs AI music creator
                  for each section
                  of your composition (e.g., intro and verse, or verse and chorus).
                </div>


                <div class="tip-box">
                  <p><strong>Treat each section as its own mini-composition.</strong> Be specific in your
                    descriptions to help the AI generate distinct aspects of each section.
                  </p>
                </div>
                <br>
                <p>Follow these steps (repeat for each section):</p>
                <ol>
                  <li>
                    Go to <a href="https://chatgpt.com/" target="_blank">ChatGPT</a> and start a new conversation.
                    <ul>
                      <li>Explain that you want to create an AI-generated music section, for example, an intro section
                        for your
                        1â€“1.5 minute composition.</li>
                      <li>Ask ChatGPT to ask you the following questions <strong>one at a time</strong> about:</li>
                      <ul>
                        <li>Instruments or sonic textures</li>
                        <li>Musical structure an length of each section</li>
                        <li>Mood / emotional tone of the section</li>
                      </ul>
                      <li>See example below:
                        <v-img src="images/AIMusic/prompt_section1.png" alt="ChatGPT prompt example"
                          class="my-4 rounded-lg" width="60%" />
                      </li>
                    </ul>
                  </li>

                  <li>
                    Answer ChatGPTâ€™s questions thoughtfully, providing detailed descriptions for each
                    section.
                    <v-img src="images/AIMusic/prompt_section2.png" alt="ChatGPT response example"
                      class="my-4 rounded-lg" width="60%" />
                  </li>

                  <li>
                    Once all questions are answered, ask ChatGPT to generate a list of concise, clear prompts for
                    ElevenLabs that can be directly input <b>to produce only that section</b>.
                    <v-img src="images/AIMusic/prompt_section3.png" alt="ElevenLabs prompt example"
                      class="my-4 rounded-lg" width="60%" />
                  </li>

                  <li>
                    Save your prompts for this section in a notepad or Word document for later submission in step 6.
                    <v-img src="images/AIMusic/prompt_section4.png" alt="ElevenLabs prompt example"
                      class="my-4 rounded-lg" width="50%" />
                  </li>
                  <li>
                    Repeat the entire process for your second section (e.g., if you
                    started with the intro, repeat for the verse).
                    <v-img src="images/AIMusic/prompt_section5.png" alt="ElevenLabs prompt example"
                      class="my-4 rounded-lg" width="60%" />
                  </li>

                </ol>


              </div>



              <div class="section-divider"></div>
              <div class="step-section">

                <h3><v-icon color="primary" class="mr-2">mdi-music-note</v-icon>Step 4: Generate Sections in ElevenLabs
                </h3>
                <div class="objective-box">
                  <strong>Objective:</strong> Use the prompts you developed with ChatGPT to generate each section of
                  your composition in ElevenLabs AI music creator, and save the resulting audio file.
                </div>


                <p>Follow these steps for each section (e.g., intro and verse or verse and chorus):</p>
                <ol>
                  <li>Go to <a href="https://www.elevenlabs.io/" target="_blank">ElevenLabs AI music creator</a> and
                    click <strong>Log in</strong>.</li>

                  <li>
                    Enter the prompts you generated with ChatGPT for the current section.
                    <ul>

                    </ul>
                  </li>

                  <li>
                    Click <strong>Generate</strong> to produce your section.
                    <ul>
                      <li>Listen critically using the play button.</li>
                      <li><strong>Recommendation:</strong> Avoid tweaking prompts immediately to conserve your monthly
                        generation minutes. Save them for refinement if needed later.
                      <li><v-img src="images/AIMusic/elevenlabs_section1.png" alt="ElevenLabs prompt example"
                          class="my-4 rounded-lg" width="60%" /></li>
                  </li>
                  </ul>
                  </li>

                  <li>
                    <strong>Adding a New Section:</strong>
                    <ul>
                      <li>To insert a section between existing ones, hover over the section in the section view and
                        click the â€+ Add Sectionâ€ icon that appears. This will add a section after the current section.
                      </li>
                      <!-- <li>To add a section at the end of your track, scroll to the end of the timeline and click the â€+â€
                        button.</li> -->
                      <li>Drag the new section in the timeline to adjust its duration.</li>
                      <li><v-img src="images/AIMusic/elevenlabs_section2.png" alt="ElevenLabs prompt example"
                          class="my-4 rounded-lg" width="60%" /></li>
                    </ul>
                  </li>

                  <li>
                    <strong>Removing a Section:</strong>
                    <ul>
                      <li>Hover over the section you wish to remove in the song structure view.</li>
                      <li>Click the delete icon (X) that appears in the corner of the section block.</li>
                      <li><v-img src="images/AIMusic/elevenlabs_section3.png" alt="ElevenLabs prompt example"
                          class="my-4 rounded-lg" width="60%" /></li>
                    </ul>
                  </li>
                </ol>
              </div>

              <div class="section-divider"></div>
              <div class="step-section">

                <h3><v-icon color="primary" class="mr-2">mdi-share-variant</v-icon>Step 5: Save Your Composition for
                  Later Posting on the Discussion Forum</h3>
                <div class="objective-box">
                  <strong>Objective:</strong> Save your AI-generated composition for later posting to the discussion
                  forum
                  <strong>Part 2: Materials Collection</strong>.
                </div>

                <p>Follow these steps:</p>
                <ol>
                  <li>
                    Copy the <strong>Share Page</strong> link from ElevenLabs.
                    <ul>
                      <li>Click the <strong>Share</strong> button at the bottom of ElevenLabs Music Creator.</li>
                      <li>Select <strong>Share Public Page</strong>.
                        <v-img src="images/AIMusic/elevenlabs3.png" alt="ElevenLabs share button"
                          class="my-4 rounded-lg" width="60%" />
                      </li>
                    </ul>
                  </li>

                  <li>
                    Save this Public Page link for posting in the discussion forum <strong>Part 2: Materials
                      Collection</strong> in the step 6 below.
                    <ul>
                      <li>Ensure your post includes the composition containing two sections (e.g., intro and verse or
                        verse and chorus).</li>
                    </ul>
                  </li>

                </ol>


              </div>

              <div class="section-divider"></div>
              <div class="step-section">

                <h3><v-icon color="primary" class="mr-2">mdi-file-document-outline</v-icon>Step 6: Document Your Work
                  for Project 2, Part 2: Materials Collection</h3>

                <div class="objective-box">
                  <strong>Objective:</strong> Prepare documentation of your creative process and AI-generated materials
                  for submission in
                  <strong>Project 2, Part 2: Materials Collection</strong> on LEARN. This documentation will help you
                  articulate your prompt decisions,
                  reflect on AI-human collaboration, and plan for your final musical composition.
                </div>

                <p>Take notes on the following to prepare for your forum post:</p>

                <ol>
                  <li><strong>For each of your prompts provide:</strong>
                    <ul>
                      <li>Short annotation (1â€“2 sentences) explaining the creative intent behind the prompt or question.
                      </li>
                      <li>Describe what musical ideas (instruments, structure, and mood) the prompt is meant to explore.
                      </li>
                    </ul>
                  </li>

                  <li><strong>Brief reflection (2â€“3 sentences):</strong>
                    <ul>
                      <li>Discuss how your generated sections connect to your proposal and course ideas about AI,
                        automation, and creativity.</li>
                      <li>Reflect on how the AI collaboration influenced your musical decisions.</li>
                      <li>Consider how these initial explorations might shape your final composition.</li>
                    </ul>
                  </li>
                </ol>

                <br>

                <div class="tip-box">
                  <p><strong>ðŸ’¡ Ready to Submit?</strong></p>
                  <p>You now have everything you need for <a
                      href="https://gbdawu.github.io/gbda412/group-project-2.html" target="_blank"> Project 2, Part 2:
                      Materials
                      Collection</a>:</p>
                  <ul>
                    <li>âœ… PDF or Word document containing the final prompts for each section (submit only the final
                      prompts not the whole conversation)</li>
                    <li>âœ… Share Page link from ElevenLabs containing your 1 - 1.5 minute composition (intro + verse or
                      verse + chorus)</li>
                    <li>âœ… Documentation with short annotations for each prompt</li>
                    <li>âœ… Brief reflection connecting your work to your proposal and course concepts</li>
                  </ul>
                  <p>Post your materials in the discussion forum <strong>Part 2: Materials
                      Collection</strong> on LEARN by the deadline. Consult detailed guidelines here: <a
                      href="https://gbdawu.github.io/gbda412/group-project-2.html" target="_blank"> Project 2, Part 2:
                      Materials
                      Collection</a></p>
                </div>

              </div>


            </v-window-item>

            <!-- Workshop 3 -->
            <v-window-item :value="6">
              <h2>{{ streamBWorkshops[2].title }}</h2>

              <div class="intro-section">
                <p>
                  In this workshop, you will combine your AI prompting skills and ElevenLabs editing to produce a
                  complete song.
                  You will practice structuring a longer composition of <strong>2-3 minutes</strong>, starting with a
                  full-song prompt in ChatGPT,
                  and then refining sections directly in ElevenLabs. Through this process, youâ€™ll learn a workflow you
                  can use for your final assignment.
                </p>
                <br>


                <h3>
                  <v-icon color="primary" class="mr-2">mdi-music-note</v-icon>
                  What You Will Do
                </h3>

                <p>
                  In this workshop, you will generate a full song prompt using ChatGPT. You will also experiment with
                  editing individual sections directly in ElevenLabs
                  to enhance your composition.
                </p>
                <br>

                <div class="learning-objectives">
                  <h3>
                    <v-icon color="primary" class="mr-2">mdi-alert-circle-outline</v-icon>
                    Subscription Disclaimer
                  </h3>


                  <p>If you choose to explore the topic of AI music, please note that you may need to upgrade to the $5
                    USD one-month subscription of ElevenLabs. In many cases, the free version may be
                    sufficient, but the subscription could be necessary to fully complete the assignment. Alternative
                    options include changing to Stream A which uses free software.</p>
                </div>

                <div class="learning-objectives">
                  <h3><v-icon color="primary" class="mr-2">mdi-target</v-icon>Learning Objectives</h3>
                  <ul>
                    <li>Develop skills in AI prompting for complex, multi-section compositions.</li>
                    <li>Practice refining generated music by editing individual sections in ElevenLabs.</li>
                    <li>Practice how to produce a full 2-3 minute song ready to share.</li>
                  </ul>
                </div>

                <div class="tools-section">
                  <h3><v-icon color="primary" class="mr-2">mdi-tools</v-icon>Tools you'll use</h3>
                  <ul>
                    <li>ChatGPT</li>
                    <li>ElevenLabs</li>
                  </ul>
                </div>

              </div>

              <!-- Steps -->
              <div class="section-divider"></div>
              <div class="step-section">
                <h3><v-icon color="primary" class="mr-2">mdi-notebook-edit</v-icon>Step 1: Generate A Full-Song Prompt
                  With ChatGPT</h3>

                <div class="objective-box">
                  <strong>Objective:</strong> Create a detailed prompt for your full 2-3 minute song using ChatGPT,
                  which will guide the AI-generated composition in ElevenLabs.
                </div>

                <ol>
                  <li>
                    <strong>Follow the video tutorial to create a full-song prompt in ChatGPT.</strong>
                    <br>
                    <div class="tip-box">
                      <p> ðŸ’¡ Pay attention to how the use ChatGPT to include details such as genre, mood,
                        instrumentation, structure
                        (intro, verse,
                        chorus, outro), and any other creative specifications.</p>
                    </div>

                  </li>
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/r3ctNrWzRLQ?si=eBx2gJPNPY3Q5z5M"
                    title="YouTube video player" frameborder="0"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                    referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

                  <div class="tip-box">
                    <strong>ðŸ’¡ Tip:</strong> Use the glossary to describe musical elements accurately and expand your
                    prompts with clear musical terminology.

                    <!-- Collapsible glossary section -->
                    <ul>
                      <li><strong>Tempo:</strong> The speed of the music, measured in beats per minute (BPM).</li>
                      <li><strong>Harmony:</strong> The combination of different musical notes played simultaneously.
                      </li>
                      <li><strong>Melody:</strong> A sequence of musical notes that forms the main theme of a song.
                      </li>
                      <li><strong>Rhythm:</strong> The pattern of sounds and silences in music.</li>
                      <li><strong>Key:</strong> The main set of notes a song is based on. For example, a song in
                        the key of C mostly uses notes from the C scale.</li>
                      <li><strong>Scale:</strong>A series of notes arranged in order from low to high (or high to low).
                        Scales help define the mood of a songâ€”for example, major scales often sound bright or happy,
                        while minor scales sound sad or more emotional.
                      </li>
                      <li><strong>Chord:</strong> A group of notes played together that harmonize.</li>
                      <li><strong>Panning:</strong> The placement of sound in the stereo field (left or right).</li>
                      <li><strong>Volume:</strong> The loudness or softness of a sound.</li>
                      <li><strong>Verse:</strong> A section with lyrics that usually change each time it appears.</li>
                      <li><strong>Chorus:</strong> A repeated section with the same lyrics and melody.</li>
                      <li><strong>Bridge:</strong> A contrasting section connecting different parts of the song.</li>
                      <li><strong>Fills:</strong> Short passages used to transition between sections.</li>
                      <li><strong>Intro:</strong> The opening section of a song.</li>
                      <li><strong>Outro:</strong> The ending section of a song.</li>
                    </ul>

                  </div>

                </ol>
              </div>


              <div class="section-divider"></div>
              <div class="step-section">
                <h3><v-icon color="primary" class="mr-2">mdi-notebook-edit</v-icon>Step 2: Generate Your Song in
                  ElevenLabs</h3>

                <div class="objective-box">
                  <strong>Objective:</strong> Use your completed ChatGPT prompt to generate a full 2â€“3 minute song in
                  ElevenLabs, adjusting generation settings to shape your composition before moving on to section
                  editing.
                </div>

                <ol>

                  <li>
                    <strong>Configure duration settings before generating the song:</strong>
                    <ul>
                      <li>Adjust the song duration to meet the requirement of 2â€“3 minutes. ElevenLabs will only generate
                        30 seconds by default unless adjusted to 2 or 3 minutes.</li>
                      <v-img src="images/AIMusic/length.png" alt="ElevenLabs share button" class="my-4 rounded-lg"
                        width="60%" />
                    </ul>
                  </li>

                  <li>
                    <strong>Configure generation variants to only 1:</strong>
                    <ul>
                      <li>Change the variant number to 1. This way, ElevenLabs will only generate one song from your
                        prompt which will allow you to save credits.</li>
                      <v-img src="images/AIMusic/variant.png" alt="ElevenLabs share button" class="my-4 rounded-lg"
                        width="60%" />

                    </ul>
                  </li>

                  <li>
                    <strong>Generate your full song in ElevenLabs:</strong>
                    <ul>
                      <li>Paste your completed prompt into the ElevenLabs Music Generation tool.</li>
                      <li>Ensure core elementsâ€”intro, verse, chorus, and outroâ€”are represented in the generated output.
                      </li>
                    </ul>
                  </li>

                </ol>
              </div>

              <div class="section-divider"></div>
              <div class="step-section">
                <h3><v-icon color="primary" class="mr-2">mdi-notebook-edit</v-icon>Step 3: Refine Your Song in
                  ElevenLabs</h3>

                <div class="objective-box">
                  <strong>Objective:</strong> Edit and enhance the sections of your generated song to improve musical
                  expression and production quality.
                </div>

                <ol>
                  <li>
                    <strong>Follow the official ELevenLabs video (starting in minute
                      1:47) to edit individual sections such as intro, verse, chorus, and outro</strong>.

                    <ul>
                      <li>Adjust musical elements like melody, rhythm, and harmony where needed.</li>
                      <li>Experiment with dynamics, volume, and panning to create depth and balance in your song.</li>
                      <li>Add or adjust effects to shape the overall sound of each section.</li>


                      <iframe width="560" height="315"
                        src="https://www.youtube.com/embed/MCrkItqdRRI?si=4MUim99vhxdhXhRf&amp;start=107"
                        title="YouTube video player" frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                        referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    </ul>
                  </li>
                </ol>
              </div>

            </v-window-item>


          </v-window>

        </v-container>
      </v-main>
    </v-app>
  </div>
  <script src="appProjectTwo.js"></script>

</body>

</html>